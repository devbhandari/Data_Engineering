{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae11c74e-2114-48c5-a292-8a5100824c43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>firstname</th><th>lastname</th><th>salary</th><th>bonus</th></tr></thead><tbody><tr><td>1</td><td>Ram</td><td>Singh</td><td>2000</td><td>500</td></tr><tr><td>2</td><td>Shyam</td><td>Rawat</td><td>10000</td><td>700</td></tr><tr><td>3</td><td>Mohan</td><td>Kumar</td><td>3000</td><td>300</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Ram",
         "Singh",
         2000,
         500
        ],
        [
         2,
         "Shyam",
         "Rawat",
         10000,
         700
        ],
        [
         3,
         "Mohan",
         "Kumar",
         3000,
         300
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 40: UDF in pyspark\n",
    "#udf is similar to the function in any other language like (sql,java,C etc.)\n",
    "# similar to sql function, you can write code and save it in database and then reuse this in code wherever is need\n",
    "\n",
    "data =[(1,'Ram','Singh',2000,500),(2,'Shyam','Rawat',10000,700),(3,'Mohan','Kumar',3000,300)]\n",
    "sch=['id','firstname','lastname','salary','bonus']\n",
    "df=spark.createDataFrame(data,sch)\n",
    "display(df)\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a6bfa3f-f11e-4b22-b276-01e180a29a2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#create function and register it\n",
    "from pyspark.sql.types import IntegerType,StringType\n",
    "from pyspark.sql.functions import udf\n",
    "@udf(returnType=IntegerType())\n",
    "def total_sal(base_Sal,bonus):\n",
    "    return base_Sal+bonus\n",
    "@udf(returnType=StringType())\n",
    "def fullname(fname,lname):\n",
    "    return(fname + ' '+lname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2499255e-3a89-47b1-a0a0-bbf7b0cd08fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------+-----+-------------+----------------+\n| id|firstname|lastname|salary|bonus|Emp_Full_Name|total_emp_salary|\n+---+---------+--------+------+-----+-------------+----------------+\n|  1|      Ram|   Singh|  2000|  500|    Ram Singh|            2500|\n|  2|    Shyam|   Rawat| 10000|  700|  Shyam Rawat|           10700|\n|  3|    Mohan|   Kumar|  3000|  300|  Mohan Kumar|            3300|\n+---+---------+--------+------+-----+-------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select('*',\\\n",
    "          fullname(df.firstname,df.lastname).alias('Emp_Full_Name'),\\\n",
    "          total_sal(df.salary,df.bonus).alias('total_emp_salary')\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd8bbb1-5939-4cef-9e15-6aca03e6573f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------+-----+\n| id|firstname|lastname|salary|bonus|\n+---+---------+--------+------+-----+\n|  1|      Ram|   Singh|  2000|  500|\n|  2|    Shyam|   Rawat| 10000|  700|\n|  3|    Mohan|   Kumar|  3000|  300|\n+---+---------+--------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#now lets play the functions with tempview\n",
    "# df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0c9a4b-6f08-44ca-9bb9-840aedd29b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data =[(1,'Ram','Singh',2000,500),(2,'Shyam','Rawat',10000,700),(3,'Mohan','Kumar',3000,300)]\n",
    "sch=['empid','firstname','lastname','salary','bonus']\n",
    "df=spark.createDataFrame(data,sch)\n",
    "df.createOrReplaceTempView('emps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8788a1-efbd-4994-945f-002d6bda7dee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empid</th><th>firstname</th><th>lastname</th><th>salary</th><th>bonus</th></tr></thead><tbody><tr><td>1</td><td>Ram</td><td>Singh</td><td>2000</td><td>500</td></tr><tr><td>2</td><td>Shyam</td><td>Rawat</td><td>10000</td><td>700</td></tr><tr><td>3</td><td>Mohan</td><td>Kumar</td><td>3000</td><td>300</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Ram",
         "Singh",
         2000,
         500
        ],
        [
         2,
         "Shyam",
         "Rawat",
         10000,
         700
        ],
        [
         3,
         "Mohan",
         "Kumar",
         3000,
         300
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empid",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from emps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8e9dea-cde9-4116-b4bf-a461868a99f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[26]: <function __main__.fullname(fname, lname)>"
     ]
    }
   ],
   "source": [
    "# Now register the udf to use in sql with tempview\n",
    "def total_sal(base_Sal,bonus):\n",
    "    return base_Sal+bonus\n",
    "def fullname(fname,lname):\n",
    "    return(fname + ' '+lname)\n",
    "# register functions\n",
    "spark.udf.register(name='Total_Salary_SQL',f=total_sal,returnType=IntegerType())\n",
    "spark.udf.register(name='Full_Name_SQL',f=fullname,returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054efc40-6ee0-4a9c-947b-1666587dbdd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empid</th><th>firstname</th><th>lastname</th><th>FullName</th><th>salary</th><th>bonus</th><th>Total_Sal</th></tr></thead><tbody><tr><td>1</td><td>Ram</td><td>Singh</td><td>Ram Singh</td><td>2000</td><td>500</td><td>2500</td></tr><tr><td>2</td><td>Shyam</td><td>Rawat</td><td>Shyam Rawat</td><td>10000</td><td>700</td><td>10700</td></tr><tr><td>3</td><td>Mohan</td><td>Kumar</td><td>Mohan Kumar</td><td>3000</td><td>300</td><td>3300</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Ram",
         "Singh",
         "Ram Singh",
         2000,
         500,
         2500
        ],
        [
         2,
         "Shyam",
         "Rawat",
         "Shyam Rawat",
         10000,
         700,
         10700
        ],
        [
         3,
         "Mohan",
         "Kumar",
         "Mohan Kumar",
         3000,
         300,
         3300
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empid",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "FullName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Total_Sal",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- use the above two funcitons in sql\n",
    "SELECT empid,firstname,lastname,Full_Name_SQL(firstname,lastname) as FullName,\n",
    "salary,bonus,Total_Salary_SQL(salary,bonus) as Total_Sal \n",
    "from emps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38d54a3f-81ed-486c-bc33-4bddb5921859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Ram', 'Singh', 2000, 500), (2, 'Shyam', 'Rawat', 10000, 700), (3, 'Mohan', 'Kumar', 3000, 300)]\n"
     ]
    }
   ],
   "source": [
    "# 41: Convert RDD to Dataframe\n",
    "# RDD: Resilient Distributed Dataframe: similar to list in python and its immutable and does in memory processing. however dataframe is like a table\n",
    "# using parallelize() function of sparkcontext you can create a RDD\\\n",
    "data =[(1,'Ram','Singh',2000,500),(2,'Shyam','Rawat',10000,700),(3,'Mohan','Kumar',3000,300)]\n",
    "rdd=spark.sparkContext.parallelize(data)\n",
    "# print(type(rdd))\n",
    "print(rdd.collect()) # we can get data using collect function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2fe02e-cf2f-4b47-a952-13bb37da0d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+------+-----+\n|empid|firstname|lastname|salary|bonus|\n+-----+---------+--------+------+-----+\n|    1|      Ram|   Singh|  2000|  500|\n|    2|    Shyam|   Rawat| 10000|  700|\n|    3|    Mohan|   Kumar|  3000|  300|\n+-----+---------+--------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# convert rdd to df\n",
    "df=rdd.toDF(['empid','firstname','lastname','salary','bonus'])\n",
    "df.show()\n",
    "# u can use spark.createDataframe(rdd,schema) this way to convert RDD to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "892ee04b-cbaa-46ee-8a7d-c8b2543510a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 42: Map transformation in pyspark"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1541357542922724,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_From_UDP_Onwards",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}